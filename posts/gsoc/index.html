<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-09-12">
<meta name="description" content="An account of my Google Summer of Code experience.">

<title>Giles Harper-Donnelly - Google Summer of Code 2022</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Giles Harper-Donnelly</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gileshd" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gileshd" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Google Summer of Code 2022</h1>
                  <div>
        <div class="description">
          An account of my <em>Google Summer of Code</em> experience.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 12, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<!-- ![](https://upload.wikimedia.org/wikipedia/commons/7/7c/Google_Summer_of_Code_sun_logo_2022.svg){width=200px fig-align="center"} -->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://summerofcode.withgoogle.com/assets/media/logo.svg" class="img-fluid figure-img" width="800"></p>
</figure>
</div>
<p><a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> (GSOC) is an annual program which aims to get people involved in open-source software development. Every year it matches new contributors with hundreds of different open-source organisations. Under the guidance of a mentor, contributors spend ~12 weeks over the summer working on an open-source project as part of their chosen organisation.</p>
<p>In the spring of 2022 I was nearing the end of the write-up of my PhD and GSOC felt like a great fit for the coming summer. Not only would it be a good opportunity to improve my technical skills and get some experience working collaboratively on a code-base, but I was also aware of how much I had benefited from the work of the open-source community during my PhD and was excited at the opportunity being able to contribute something back. <!--# Change this sentence / just remove it? --> <!-- I am happy to say that I was not disappointed. --></p>
<!-- This just sounds fucking stupid. -->
<p>I was lucky enough to be selected to work as part of the Google TensorFlow organisation and was mentored by <a href="https://twitter.com/sirbayes">Kevin Murphy</a> and <a href="https://web.stanford.edu/~swl1/">Scott Linderman</a>. <!-- List? --> My work over the summer consisted of:</p>
<!-- This sort of works: -->
<div style="font-family: mainfont; font-size: 105%">
<ul>
<li>Contributing to Kevin’s textbook <a href="https://probml.github.io/pml-book/book2.html"><em>Probabilistic Machine Learning: Advanced Topics</em></a>.</li>
<li>Implementing Gaussian belief propagation in <a href="https://github.com/google/jax">JAX</a>.</li>
<li>Assisting in the development of <a href="https://github.com/probml/dynamax">dynamax</a> - a library for efficient inference and learning for state-space models.</li>
</ul>
</div>
<p>I had a great time working on these projects and learnt a huge amount while doing so. This post details some of my experiences during the summer and serves as a record of the work that I undertook for GSOC admin purposes.</p>
<section id="the-book" class="level2">
<h2 class="anchored" data-anchor-id="the-book">The Book</h2>
<p>During the first part of the summer my time was predominantly spent helping with the final stages of the development of the (excellent<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>) textbook <a href="https://probml.github.io/pml-book/book2.html"><em>Probabilistic Machine Learning: Advanced Topics</em></a> (Murphy, 2023), the follow-up to the (also excellent) <a href="https://probml.github.io/pml-book/book1.html"><em>Probabilistic Machine Learning: An Introduction</em></a> (Murphy, 2021).</p>
<!--# Not sure how to center align the caption. -->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./media/pml2-cover.jpeg" class="img-fluid figure-img" width="350"></p>
<figcaption class="figure-caption">Probabilistic Machine Learning: Advanced Topics</figcaption>
</figure>
</div>
<p>A brilliant thing about these books is that a frankly ridiculous<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> number of the figures have associated colab notebooks which demonstrate the code used to generate them. This is a fantastic resource for anyone looking to implement the methods described in the book and is the product of a huge amount of work by a large number of <a href="https://github.com/probml/pyprobml/graphs/contributors">contributors</a>. I would highly recommend checking them out.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>My first contribution to the book was actually made during the GSOC selection process. As part of my application to work on this project I wrote a <a href="https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/book2/04/rbm_contrastive_divergence.ipynb">notebook</a> demonstrating training a Restricted Boltzmann Machine using Contrastive Divergence in JAX. Some figures from this notebook, one of which is reproduced below, are included in the book.</p>
<!-- Figure? -->
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./media/rbm_mnist_samples.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Samples from a Restricted Boltzmann Machine trained with constrastive divergence on MNIST</figcaption>
</figure>
</div>
<p>After the start of the GSOC process my contributions to the book focussed more on the topic of state-space models. To provide some context for the rest of this post it will be helpful to quickly cover some background.</p>
<section id="state-space-models" class="level3">
<h3 class="anchored" data-anchor-id="state-space-models">State-Space Models</h3>
<p>A state-space model is characterised by a hidden state, <span class="math inline">\(\mathbf{z}_t\)</span>, which evolves over time according to a Markov process. At each time step<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> observations, <span class="math inline">\(\mathbf{y}_t\)</span>, are generated conditional on the current value of the hidden state. This process can be represented graphically as follows:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./media/ssm-dag.png" class="img-fluid figure-img" width="220"></p>
<figcaption class="figure-caption">Graphical representation of a state-space model</figcaption>
</figure>
</div>
<p>State-space models are interesting because they can be used to model a wide variety of phenomena and, importantly, there exist powerful algorithms for performing inference. These algorithms take advantage of the Markovian structure of the model to efficiently calculate the posterior distribution over the hidden state given a sequence of observations.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>The state-space formulation is very general and encompasses many well-known model families. For instance, if we restrict the hidden state to taking only discrete values, <span class="math inline">\(z_t \in \{1, \dots, K\}\)</span>, we get a Hidden Markov Model. The family of models that I focussed over the summer was linear Gaussian state-space models.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> In these models the hidden state is continuous, <span class="math inline">\(\mathbf{z}_t \in \mathbb{R}^D\)</span>, and the transition and observation functions are linear transformations, <span class="math display">\[
\begin{align}
    \mathbf{z}_{t} &amp;= \mathbf{F}_t \mathbf{z}_{t-1} + \mathbf{b}_t + \mathbf{q}_t,\\
    \mathbf{y}_t &amp;= \mathbf{H}_t \mathbf{z}_t + \mathbf{d}_t + \mathbf{r}_t
\end{align}
\]</span> where <span class="math inline">\(\mathbf{q}_t\)</span>, <span class="math inline">\(\mathbf{r}_t\)</span>, are Gaussian noise vectors, <span class="math display">\[
\begin{align}
    \mathbf{q}_t &amp;\sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_t),\\
    \mathbf{r}_t &amp;\sim \mathcal{N}(\mathbf{0}, \mathbf{R}_t).
\end{align}
\]</span> Gaussians are robust and amiable<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> distributions, if we start with a Gaussian prior on the first hidden state, all the subsequent conditional distributions will also be Gaussian<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> <span class="math display">\[
\begin{align}
    p(\mathbf{z}_0) &amp;= \mathcal{N}(\mathbf{z}_0 \,|\, \boldsymbol{\mu}_0, \boldsymbol{\Sigma}_0),\\
    p(\mathbf{z}_t \,|\, \mathbf{z}_{t-1}) &amp;= \mathcal{N}(\mathbf{z}_t \,|\, \mathbf{F}_t \mathbf{z}_{t-1} + \mathbf{b}_t, \mathbf{Q}_t),\\
    p(\mathbf{y}_t \,|\, \mathbf{z}_t) &amp;= \mathcal{N}(\mathbf{y}_t \,|\, \mathbf{H}_t \mathbf{z}_t + \mathbf{d}_t, \mathbf{R}_t).
\end{align}
\]</span> <!-- TODO: FINISH THIS SENTENCE --> <!-- The joint is also MVN. --></p>
<p>Inference in state-space models is often divided into two types of problems, known as <em>filtering</em> and <em>smoothing</em>, which differ on the time points which are used to infer the hidden state. Filtering calculates the posterior distribution of the hidden state at some time, <span class="math inline">\(t\)</span>, conditioned on all the observations up to and including this time point, <span class="math inline">\(p(\mathbf{z}_t | \mathbf{y}_{1:t})\)</span>. In linear Gaussian state-space models, the algorithm for filtering is the famous Kalman filter. In contrast, smoothing uses information from subsequent observations, up to some future time-point <span class="math inline">\(T&gt;t\)</span>, to inform the estimate of the hidden state, <span class="math inline">\(p(\mathbf{z}_t | \mathbf{y}_{1:T})\)</span>.</p>
<p>Alongside helping out with code examples for the figures I was able to contribute to the book itself with a modest sub-(sub-sub-)section containing some derivations for <em>information-form</em> filtering and smoothing in linear Gaussian state-space models.</p>
<p>The <em>information</em>, or <em>canonical</em>, form of a multivariate Gaussian is an alternative parameterisation to the standard <em>moment</em> form in which the mean vector, <span class="math inline">\(\boldsymbol{\mu}\)</span>, and covariance matrix, <span class="math inline">\(\boldsymbol{\Sigma}\)</span>, are replaced with the precision-weighted mean<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>, <span class="math inline">\(\boldsymbol{\eta}\)</span>, and the precision matrix, <span class="math inline">\(\boldsymbol{\Lambda}\)</span>. The relationship between these parameterisations is: <span class="math display">\[
\begin{align}
    \boldsymbol{\eta} &amp;= \boldsymbol{\Lambda}\boldsymbol{\mu},\\
    \boldsymbol{\Lambda} &amp;= \boldsymbol{\Sigma}^{-1}.
\end{align}
\]</span></p>
<p>The information-form parameters are the <em>natural parameters</em> of the Gaussian, and, while their values can be a bit more difficult to directly interpret than the mean and covariance, working in this form makes certain calculations considerably more straight-forward.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>It was a real pleasure to be involved in the book project and it provided a some great learning opportunities. Getting lots of practice manipulating multivariate Gaussians was a valuable exercise and comes with a certain sort of ascetic satisfaction.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> Learning more about the relationship between the two parameterisations, and the natural parameters of exponential family distributions more generally, was satisfying in a slightly more indulgent sense and is something which I might even write a post about in the future.</p>
</section>
</section>
<section id="implementing-gaussian-belief-propagation-in-jax" class="level2">
<h2 class="anchored" data-anchor-id="implementing-gaussian-belief-propagation-in-jax">Implementing Gaussian Belief Propagation in Jax</h2>
<p>One of the principal code projects I worked on during the summer was to develop an implementation of <em>Gaussian belief propagation</em> in <a href="https://github.com/google/jax">JAX</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./media/gaussian-bp-1D-dpi-300.gif" class="img-fluid figure-img" width="600"></p>
<figcaption class="figure-caption">Loopy Gaussian belief propagation in 1D</figcaption>
</figure>
</div>
<p>The project fit well with the topics I was working on in the book, presented some interesting implementation challenges, and taught me some valuable lessons. <!-- TODO: Fix this sentence? --> In order to explain why, it will be helpful to quickly cover some background.</p>
<section id="gaussian-belief-propagation" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-belief-propagation">Gaussian Belief Propagation</h3>
<!-- #### Messaging passing algorithms -->
<p>Gaussian belief propagation is an example of a <strong>message passing</strong> algorithm.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> At a high level, message passing algorithms solve big, hard, problems by breaking them up into many smaller, easier, problems. Solutions to these sub-problems are found and the results are combined (by passing messages) to reconstitute a solution to the original problem.</p>
<p>Problems in statistics often boil down to performing calculations on probability distributions. For instance, given a probabilistic model of a process, you might want to calculate the marginal distribution of some quantity of interest conditioned on data. In difficult problems these calculations often involve large or otherwise unwieldy distributions. The way in which calculations involving probability distributions can be broken up into smaller problems is determined by the conditional independence structure of the distributions.</p>
<p>Graphical models represent the conditional independence structure of a probability distribution as a graph. Message passing algorithms then consist of performing calculations for each node (or clique) in this graph and passing messages between nodes to combine the results.</p>
<p>A particularly important message-passing algorithm is the <strong>sum-product algorithm</strong>. The sum-product algorithm calculates the marginal distributions of unobserved variables conditioned on values of the observed variables. The distributions calculated for each node are sometimes called <em>belief states</em> and so this message passing algorithm is also known as <strong>belief propagation</strong>. Message passing is a broad framework and many well-known algorithms can be expressed as message passing algorithms. This includes the Kalman filter for inference in linear Gaussian state-space models, mentioned above, which can be formulated as an example of a belief propagation algorithm.</p>
<!-- #### Messaging passing with Gaussian distributions -->
<p>In Gaussian distributions, the conditional independence structure is determined by the sparsity pattern of the precision matrix, <span class="math inline">\(\boldsymbol{\Lambda}\)</span>. This means that it can be quite natural to work with the information form parameters as part of Gaussian belief propagation. These connections between some of the subjects I focussed on for the book (i.e.&nbsp;information form filtering and smoothing) and Gaussian belief propagation, meant that it was a natural pairing of topics for me to work on over the summer.</p>
<p>For certain graph structures<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> there exist message passing algorithms to calculate <em>exact</em> solutions. These exact algorithms carefully control the flow of messages in the graph to ensure that evidence is appropriately propagated between nodes. In other scenarios, perhaps because it is not possible given the graph structure<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>, or simply because the message passing schedule does not enforce it, evidence is allowed to circulate in a more haphazard fashion, messages travel in loops, and evidence may be double counted. In such cases, message passing provides an <em>approximate</em> solution and these algorithms are known as <em>loopy belief propagation</em>. The basic idea is to run belief propagation with loops, cross your fingers and hope that it will converge to a decent estimate. It often does.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a></p>
<p>The figure at the top of this section shows the progress of a loopy belief propagation algorithm for a simple 1D inference problem in which the value of an unknown function is inferred from measurements and a smoothness constraint. The code used in this example can be found <a href="https://github.com/probml/pgm-jax/blob/main/gaussian-loopy-bp/gauss-bp-1d-line.ipynb">here</a>.</p>
<p>Coming from a biological background, there is something reassuringly <em>messy</em> about loopy belief propagation as a distributed approach to solving a problem. None of this fancy scheduling business, just let the messages fly and see what happens.</p>
<p>When things in biology perform these types of distributed operations there is often no possibility of a central supervisor, all coordination between the different entities, different cells for instance, must be encoded in the interactions between them.</p>
<p>Furthermore, the idea of tackling a <a href="https://en.wikipedia.org/wiki/Drosophila_embryogenesis#Anterior-posterior_axis_patterning_in_Drosophila">big distributed problem</a> by solving a bunch of more straightforward local problems and <a href="https://en.wikipedia.org/wiki/Cell_signaling">communicating</a> the results is reminiscent of some of the biological phenomena I studied during my PhD.</p>
</section>
<section id="jax-implementation" class="level3">
<h3 class="anchored" data-anchor-id="jax-implementation">JAX Implementation</h3>
<p><a href="https://jax.readthedocs.io/en/latest/index.html">JAX</a> is a Python library for machine learning and scientific computing which combines autograd and <a href="https://www.tensorflow.org/xla">XLA</a>. You get automatic calculation of gradients (of any order), jit compilation, auto-vectorisation as well as native support for different hardware accelerators (GPUs and TPUs) all while writing code with a familiar numpy-style interface. There is an increasingly rich ecosystem of libraries for all sorts of specialised tasks.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a></p>
<p>By implementing Gaussian belief propagation in JAX we can take advantages of all of the helpful features described above and also open up the possibility of using it as a subroutine in other JAX code.</p>
<p>This was a rather different style of development to what I was used to from my PhD. Writing code that is intended to exist as a stand-alone implementation for others to use feels rather different to writing code that is only meant to be used as part of a particular analysis. The project also presented a variety of design challenges. These ranged from interesting problems such as how to reconcile the object-oriented nature of message passing<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> with the functional programming style of JAX to more mundane issues such as figuring out the most efficient way to extract particular blocks from a precision matrix.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<p>I learned a lot during the process about managing this type of development project but learning these lessons took time and ultimately I think it is fair to say that the final product fell a bit short of the initial (rather ambitious) goals. Having said this, I think there are a bunch of positives to have come out of this part of the project. I got great exposure to some of the more internal bits of JAX and fell in love with pytrees.</p>
<p>As it stands at the end of the summer, the implementation contains loopy belief propagation for general graphs and directed belief propagation on chain structured graphs and will serve as a great foundation for future development which I am keen to continue.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></p>
</section>
</section>
<section id="dynamax" class="level2">
<h2 class="anchored" data-anchor-id="dynamax">dynamax</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/probml/dynamax/main/logo/logo.gif" class="img-fluid figure-img" width="350"></p>
</figure>
</div>
<p>In addition to the project on Gaussian belief propagation I also worked on the development of <a href="https://github.com/probml/dynamax"><em>dynamax</em></a> - a library for efficient inference and learning in state-space models built to leverage <a href="https://github.com/google/jax">JAX</a>. This work was done alongside a <a href="https://github.com/probml/dynamax/graphs/contributors">fantastic team</a> and collaborating with them was a real highlight of the summer.</p>
<!-- After the book was sent to the publishers, my focus moved fully over to working on the development of [dynamax](https://github.com/probml/dynamax) a library for efficient inference and learning in state-space models built to leverage [JAX](https://github.com/google/jax). This work was done alongside a [fantastic team](https://github.com/probml/dynamax/graphs/contributors) and collaborating with them was a real highlight of the process. -->
<!--# Some general statement like the following: -->
<!--# It has been an enormously rewarding experience working alongside others to develop an efficient, extendable, and comprehensible code-base aimed at a general audience of ML practitioners. -->
<!--# As well as furthering my experience with the practicalities of software development, such as the use of version-control tools and automated testing frameworks, I have relished the collaborative aspect of the work -->
<p>My principle personal contributions to dynamax mirrored some of my contributions to the book and involved developing demos and implementing information-form filtering and smoothing. I was also able to get involved more generally with the development of the library and contributed to discussions about the overall structure of the code-base and the design of the API. It was really a valuable opportunity to gain experience working with a larger code-base and to learn more about the practicalities of software development, code-review, and automated testing.</p>
<p>I look forward to continue working as a maintainer on dynamax and am excited to see how it develops.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Update (Dec 2022) dynamax has now been ‘released’ and it’s <a href="https://github.com/probml/dynamax/stargazers">going well</a>!</p>
</div>
</div>
<!-- ADD FIGURE HERE -->
</section>
<section id="reflecting-on-the-experience" class="level2">
<h2 class="anchored" data-anchor-id="reflecting-on-the-experience">Reflecting on the Experience</h2>
<p>Overall I am really pleased with my GSOC experience. I learned an enormous amount and feel very fortunate to have been able to be involved in such varied and interesting projects.</p>
<p>First and foremost however, I am hugely grateful to my fellow contributors for helping to create such a great working environment and to my mentors, Kevin and Scott, for their patience, guidance, and support throughout the summer.</p>

<!--# Maybe make this into a table? -->

</section>


<div id="quarto-appendix" class="default"><section id="dynamax-prs" class="level3 appendix"><h2 class="anchored quarto-appendix-heading">dynamax PRs</h2><div class="quarto-appendix-contents">

<p>For GSOC administrative purposes, below is a collection of Pull Requests I made to the <a href="https://github.com/probml/dynamax/">dynamax repo</a><a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> during the GSOC period:</p>
<table class="table">
<thead>
<tr class="header">
<th>PRs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://github.com/probml/dynamax/pull/203">Functional Loopy bp in a Gaussian Factor Graph.</a></td>
</tr>
<tr class="even">
<td><a href="https://github.com/probml/dynamax/pull/161">Belief Propagation on a Gaussian Chain</a></td>
</tr>
<tr class="odd">
<td><a href="https://github.com/probml/dynamax/pull/62">Kalman info form marginal log likelihood and smoothing</a></td>
</tr>
<tr class="even">
<td><a href="https://github.com/probml/dynamax/pull/30">Add information form filtering.</a></td>
</tr>
<tr class="odd">
<td><a href="https://github.com/probml/dynamax/pull/27">Add online linear regression demo from JSL.</a></td>
</tr>
<tr class="even">
<td><a href="https://github.com/probml/dynamax/pull/23">Update lgssm filtering output and port lgssm demos from JSL.</a></td>
</tr>
<tr class="odd">
<td><a href="https://github.com/probml/dynamax/pull/22">Fix broadcasting in calculating emission log probs</a></td>
</tr>
<tr class="even">
<td><a href="https://github.com/probml/dynamax/pull/19">Restructure and add to tfp lgssm tests and update tracking demo.</a></td>
</tr>
</tbody>
</table>
<!---
* [Functional Loopy bp in a Gaussian Factor Graph.](https://github.com/probml/dynamax/pull/203)
* [Belief Propagation on a Gaussian Chain](https://github.com/probml/dynamax/pull/161)
* [Kalman info form marginal log likelihood and smoothing](https://github.com/probml/dynamax/pull/62)
* [Add information form filtering.](https://github.com/probml/dynamax/pull/30)
* [Add online linear regression demo from JSL.](https://github.com/probml/dynamax/pull/27)
* [Update lgssm filtering output and port lgssm demos from JSL.](https://github.com/probml/dynamax/pull/23)
* [Fix broadcasting in calculating emission log probs](https://github.com/probml/dynamax/pull/22)
* [Restructure and add to tfp lgssm tests and update tracking demo.](https://github.com/probml/dynamax/pull/19)
-->


</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I’m biased, but honestly it is very good.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>more than <a href="https://github.com/probml/pyprobml/blob/auto_notebooks_md/notebooks.md">500</a>!<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>pdfs for both books are available for free <a href="https://probml.github.io/pml-book/">here</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>we’ll restrict ourselves to discrete time systems here<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>The lingo in the field refers to this process as <em>inference</em>. The term <em>learning</em> is used to refer to the process of using data to estimate model parameters values. I initially found this a bit confusing because, if you are Bayesian enough, everything is inference. It does however reflect the fact that, in practice, most of the time learning is a matter of calculating point estimates rather than posterior distributions.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Also known as a Linear Dynamical Systems<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>like Hagrid<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>In other words, the family of Gaussian distributions is closed under affine transformations.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>also known as the <em>potential</em> or <em>information</em> vector<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>Given the parameters of the joint distribution in moment form, it is easy to calculate the parameters of the marginal distributions, they can simply be extracted from the mean vector and covariance matrix. This is part of the reason it is easy to directly interpret the significance of parameter values in this form. Conversely, it is difficult to calculate the parameters of a conditional distribution in moment form (difficult in the sense that it involves a matrix inverse). This is the other way round for information form, where it is difficult to calculate the parameters of a marginal distribution but it is straightforward to calculate the parameters of a conditional distribution.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>Eat your vegetables and do linear algebra kids.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p>We will stick to very high level details here, for a more in-depth introduction to Gaussian Belief Propagation, with great interactive visualisations, see <a href="https://gaussianbp.github.io/" target="_blank">gaussianbp.github.io</a>.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p>trees<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p>it is possible to convert any graph to have the appropriate structure, using the <em>junction-tree</em> algorithm, however that is outside the scope of both my project and the current discussion<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p>Data not shown.<a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p>see, for instance, <a href="https://jax.readthedocs.io/en/latest/building_on_jax.html">here</a> and <a href="https://github.com/google/jax#neural-network-libraries">here</a><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p>It turns out that there is a deep link between object-oriented programming and message passing (understood in the broad sense of the term). <a href="https://en.wikipedia.org/wiki/Alan_Kay">Adam Kay</a>, who coined the term “object-oriented”, later regretted this choice because he felt the “big idea” was actually the messages passed between the objects.</p>
<p>In <a href="http://worrydream.com/EarlyHistoryOfSmalltalk/"><em>The Early History Of Smalltalk</em></a>, Kay presents the history of some of these ideas. It is a considerably more engaging read than 20,000 words on the history of a programming language has any right to be and takes an endearingly philosophical perspective in many places. I heartily recommend giving it a look even if the topic doesn’t sound particularly interesting to you at first glance (it certainly didn’t to me).<a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p>Which in retrospect was a clear instance of premature optimisation.<a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><em>inshallah</em><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p>formerly known as <code>ssm-jax</code><a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/gileshd\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>